{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9344739",
   "metadata": {},
   "source": [
    "# Universal Approximation Theorem\n",
    "\n",
    "a feedforward network with a single hiddle layer and a nonlinear, bounded, continuous activation can approximate any continuous function on a compact domain to arbitrary accuracy.\n",
    "\n",
    "## Forward Pass\n",
    "process of taking an input vector x and feeding it through the network, layer by layer, to produce a final prediction $\\hat{y}$\n",
    "\n",
    "computation for every layaer follows the same two step, vectorized pattern:\n",
    "\n",
    "    - Linear Combination: \n",
    "        - zl = Wl * a(l-1) + bl\n",
    "    - Non-linear Activation:\n",
    "        - al = g(zl)\n",
    "\n",
    "    the final activation vector al is the network's prediction $\\hat{y}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d83c21",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "- For Regression Tasks:\n",
    "    - we have MSE\n",
    "    - calculates the average squared difference between true and predicted values\n",
    "    - penalizes large errors very heavily.\n",
    "\n",
    "- For Classification Tasks:\n",
    "    - we have Cross Entropy Loss\n",
    "    - L = - summation of (yc * log(y(cap c)))\n",
    "\n",
    "    - yc is 1 if c is the true class, 0 otherwise\n",
    "    - y (cap c) is the predicted probability for class c\n",
    "    - penalizes the model being confident and wrong.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8d428",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient Descent is an optimization algorithm used to minimize the loss function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient.\n",
    "\n",
    "### Steps:\n",
    "1. **Initialize Parameters**: Start with initial values for weights and biases.\n",
    "2. **Compute Gradient**: Calculate the gradient of the loss function with respect to each parameter.\n",
    "3. **Update Parameters**: Adjust parameters using the formula:\n",
    "    \\[\n",
    "    \\theta = \\theta - \\eta \\cdot \\nabla J(\\theta)\n",
    "    \\]\n",
    "    where:\n",
    "    - \\(\\theta\\) represents the parameters (weights and biases),\n",
    "    - \\(\\eta\\) is the learning rate,\n",
    "    - \\(\\nabla J(\\theta)\\) is the gradient of the loss function.\n",
    "\n",
    "4. **Repeat**: Iterate until convergence or a stopping criterion is met.\n",
    "\n",
    "### Types of Gradient Descent:\n",
    "- **Batch Gradient Descent**: Uses the entire dataset to compute the gradient.\n",
    "- **Stochastic Gradient Descent (SGD)**: Uses a single data point to compute the gradient.\n",
    "- **Mini-Batch Gradient Descent**: Uses a small batch of data points to compute the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90adc14a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9c856",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e577b4c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

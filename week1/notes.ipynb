{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa280877",
   "metadata": {},
   "source": [
    "# Building a FeedForward network\n",
    "\n",
    "1. The INput Layer\n",
    "    - receives the data and just pass values along.\n",
    "\n",
    "2. The Hidden Layers\n",
    "    - the networks's computational engine\n",
    "    - they learn increasingly abstract features\n",
    "\n",
    "3. The Output Layer\n",
    "    - produces the final result\n",
    "\n",
    "Feedforward flow: information moves in one direction only, input to output(no loops)\n",
    "\n",
    "Fully Connected: every neuron connects to every neuron in the next layer.\n",
    "\n",
    "## The Standard Forward Model: A neuron's calculation\n",
    "\n",
    "Step 1: The Linear Part(Weighted Sum)\n",
    "\n",
    "    - a weighted sum of all inputs is calculated\n",
    "    - a bias term is added to this sum\n",
    "    - result: z = (Summation of wi*xi) + b\n",
    "\n",
    "Step 2: The Non-Linear Part(activation)\n",
    "    - the result z is passed through a non-linear activation function g.\n",
    "    - this introduces complexity and allows the network to learn non-linear patterns.\n",
    "    - final output: a = g(z)\n",
    "\n",
    "\n",
    "## The Forward Pass: The vectorized layer view\n",
    "\n",
    "- Problem: Calculating neuron by neuron is incredibly inefficient.\n",
    "- Solution: compute an entire layer at once using vectorized operations(i.e., matrix mul)\n",
    "\n",
    "![image.png](../public/images/image.png)\n",
    "\n",
    "![image2.png](../public/images/image2.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b2f4d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
